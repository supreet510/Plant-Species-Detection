
ğŸŸ© 1. Imports

```
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import os
from tensorflow.keras.applications import EfficientNetV2B0
```

ğŸ”‘ Whatâ€™s happening:
Weâ€™re bringing in ready-made tools and libraries:

TensorFlow & Keras â†’ the deep-learning framework that lets us build and train the model.

Layers â†’ building blocks (like LEGO pieces) for the network.

Matplotlib â†’ for drawing graphs.

os â†’ to handle file paths.

EfficientNetV2B0 â†’ the advanced image-recognition model weâ€™re going to reuse.

ğŸ’¬ How to explain:

â€œWe start by importing tools we needâ€”like you open MS Word to write, Excel to handle tables. TensorFlow and Keras help us build and train the brain of our app. Matplotlib draws charts, and EfficientNet is a pre-trained brain weâ€™ll reuse to save time.â€


ğŸŸ© 2. Downloading and Unzipping the Dataset

```
!pip install gdown
file_id = '1HL56kxu9y0oaJhfyvkvrOYaszDGQKv_G'
file_name = 'combined_dataset.zip'
!gdown --id {file_id} -O {file_name}
!unzip -q "{file_name}" -d "/content/plant_dataset"
```

ğŸ”‘ Whatâ€™s happening:

gdown lets us download a file from Google Drive using its ID.

We download a ZIP file that has all the plant images.

We unzip (extract) the images into a folder called plant_dataset.

ğŸ’¬ How to explain:

â€œWe download the collection of plant photos and unzip them so our program can read them. Itâ€™s like downloading a folder of photos from Google Drive and opening it on the computer.â€


ğŸŸ© 3. Setting Parameters

```
BATCH_SIZE = 32
IMG_SIZE = (256, 256)
SEED = 42
data_dir = "/content/plant_dataset/combined_dataset"
```

ğŸ”‘ Whatâ€™s happening:

BATCH_SIZE: number of photos the model looks at in one step.

IMG_SIZE: we resize every photo to 256Ã—256 pixels so theyâ€™re all uniform.

SEED: fixed random seed â†’ keeps the split of train/validation data the same each time (helps reproducibility).

data_dir: folder location of images.

ğŸ’¬ How to explain:

â€œWe set a few settings: how many pictures we show the model at a time, what size we make them, and a seed so the random shuffling stays consistent.â€


ğŸŸ© 4. Loading the Dataset

```
train_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir, validation_split=0.2, subset="training",
    seed=SEED, image_size=IMG_SIZE, batch_size=BATCH_SIZE
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir, validation_split=0.2, subset="validation",
    seed=SEED, image_size=IMG_SIZE, batch_size=BATCH_SIZE
)

class_names = train_ds.class_names
num_classes = len(class_names)
print(f"Detected {num_classes} species:", class_names)
```

ğŸ”‘ Whatâ€™s happening:

TensorFlow automatically reads the images from folders and assigns labels based on the folder names.

We split the data: 80% for training the model, 20% for validation (testing as we go).

We save the species names and count.

ğŸ’¬ How to explain:

â€œThe code goes into the folders, reads all the images, and automatically knows which species each photo belongs to by the folder name. We keep 80% to teach the model and 20% aside to check how well itâ€™s learning.â€


ğŸŸ© 5. Data Augmentation

```
data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.2),
    layers.RandomZoom(0.2),
    layers.RandomBrightness(0.2),
])
```

ğŸ”‘ Whatâ€™s happening:
We create slightly changed versions of each photo:

Flip it sideways, rotate, zoom in/out, change brightness.

ğŸ’¬ How to explain:

â€œTo help the model recognize plants in different angles, lighting, or zoom levels, we automatically create variations of each photo. This way the model becomes more robust and not confused by minor changes.â€


ğŸŸ© 6. Speeding up Data Loading

```
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
```

ğŸ”‘ Whatâ€™s happening:

Cache: keeps images in memory to avoid re-reading from disk.

Shuffle: mixes images randomly so the model doesnâ€™t learn patterns from order.

Prefetch: loads next batch while the current one is training â†’ faster training.

ğŸ’¬ How to explain:

â€œWe make the loading of pictures faster and mix them up so the model doesnâ€™t just memorize the order.â€


ğŸŸ© 7. Building the Model

```
base_model = EfficientNetV2B0(include_top=False, weights="imagenet", input_shape=IMG_SIZE + (3,))
base_model.trainable = False  # freeze base model

inputs = keras.Input(shape=IMG_SIZE + (3,))
x = data_augmentation(inputs)
x = base_model(x, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3)(x)
outputs = layers.Dense(num_classes, activation="softmax")(x)

model = keras.Model(inputs, outputs)
model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-2),
              loss="sparse_categorical_crossentropy",
              metrics=["accuracy"])
```

ğŸ”‘ Whatâ€™s happening:

We load EfficientNetV2B0 that was already trained on millions of general images (ImageNet).

Freeze base_model: keep its learned knowledge, donâ€™t change it yet.

Add our own small layers (like a new head) to classify our specific plant species.

Compile model: choose optimizer (how it learns), loss function, and metric (accuracy).

ğŸ’¬ How to explain:

â€œWe start with a pre-trained brain (EfficientNet) that already knows about shapes, edges, colors from millions of images. We freeze it so we donâ€™t disturb that knowledge, then add our own small decision-making layers to recognize our plant species. We tell the model how to learn and what to measure.â€


ğŸŸ© 8. Callbacks

```
callbacks = [
    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),
    keras.callbacks.ModelCheckpoint("efficientnet_plants.keras", save_best_only=True),
    keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.2)
]
```

ğŸ”‘ Whatâ€™s happening:

EarlyStopping: stop training if it stops improving â†’ saves time and avoids overfitting.

ModelCheckpoint: save the best version of the model.

ReduceLROnPlateau: lower the learning rate if progress stalls â†’ fine tune gently.

ğŸ’¬ How to explain:

â€œThese are automatic helpers. If the model stops improving, it stops training early, saves the best version, and slows down the learning rate when needed to keep improving steadily.â€


ğŸŸ© 9. Training Phase 1 â€“ Feature Extraction

```
history = model.fit(train_ds, validation_data=val_ds, epochs=20, callbacks=callbacks)
```

ğŸ”‘ Whatâ€™s happening:

The model learns only the new top layers, keeping the base frozen.

We train for up to 20 rounds (epochs), but it can stop earlier if EarlyStopping triggers.

ğŸ’¬ How to explain:

â€œWe first train just the new part of the model to adjust it for our plant photos, keeping the old knowledge untouched.â€


ğŸŸ© 10. Fine-Tuning Phase 2

```
base_model.trainable = True
model.compile(optimizer=keras.optimizers.Adam(1e-3),
              loss="sparse_categorical_crossentropy",
              metrics=["accuracy"])
fine_tune_history = model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=callbacks)
```

ğŸ”‘ Whatâ€™s happening:

We unfreeze the base model so it can learn too, but use a much smaller learning rate to avoid wiping out its good knowledge.

This makes the model adjust its older features to fit plants better.

ğŸ’¬ How to explain:

â€œOnce the new layers are stable, we let the full brain learn togetherâ€”slowly and carefullyâ€”to fine-tune it specifically for plants.â€


ğŸŸ© 11. Evaluation
bash
```
val_loss, val_acc = model.evaluate(val_ds)
print(f"Validation Accuracy: {val_acc:.2%}")
```

ğŸ”‘ Whatâ€™s happening:
We test the final model on the 20% validation set it hasnâ€™t seen during training to measure real-world accuracy.

ğŸ’¬ How to explain:

â€œWe finally check how well the model recognizes plant species on photos it never saw before.â€


ğŸŸ© 12. Visualization
bash
```
plt.figure(figsize=(12,5))
plt.plot(history.history['accuracy'] + fine_tune_history.history['accuracy'], label='train_acc')
plt.plot(history.history['val_accuracy'] + fine_tune_history.history['val_accuracy'], label='val_acc')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
```

ğŸ”‘ Whatâ€™s happening:
We draw a graph showing accuracy over each epoch for both training and validation sets.
Helps us see improvement and detect if the model overfitted.

ğŸ’¬ How to explain:

â€œWe draw a chart to show how accuracy improved during both phases and to confirm the model is learning properly.â€
